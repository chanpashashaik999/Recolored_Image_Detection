{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Keras Pre-trained Deep Learning models for your own dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction using ConvNets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] start time - 2018-10-05 09:49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/himanshu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:48: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=/input_1, outputs=Elemwise{m...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] successfully loaded base model and model...\n",
      "[INFO] encoding labels...\n",
      "[INFO] processed - 1\n",
      "[INFO] processed - 2\n",
      "[INFO] processed - 3\n",
      "[INFO] processed - 4\n",
      "[INFO] processed - 5\n",
      "[INFO] processed - 6\n",
      "[INFO] processed - 7\n",
      "[INFO] processed - 8\n",
      "[INFO] processed - 9\n",
      "[INFO] processed - 10\n",
      "[INFO] processed - 11\n",
      "[INFO] processed - 12\n",
      "[INFO] processed - 13\n",
      "[INFO] processed - 14\n",
      "[INFO] processed - 15\n",
      "[INFO] processed - 16\n",
      "[INFO] processed - 17\n",
      "[INFO] processed - 18\n",
      "[INFO] processed - 19\n",
      "[INFO] processed - 20\n",
      "[INFO] processed - 21\n",
      "[INFO] processed - 22\n",
      "[INFO] processed - 23\n",
      "[INFO] processed - 24\n",
      "[INFO] processed - 25\n",
      "[INFO] processed - 26\n",
      "[INFO] processed - 27\n",
      "[INFO] processed - 28\n",
      "[INFO] processed - 29\n",
      "[INFO] processed - 30\n",
      "[INFO] processed - 31\n",
      "[INFO] processed - 32\n",
      "[INFO] processed - 33\n",
      "[INFO] processed - 34\n",
      "[INFO] processed - 35\n",
      "[INFO] processed - 36\n",
      "[INFO] processed - 37\n",
      "[INFO] processed - 38\n",
      "[INFO] processed - 39\n",
      "[INFO] processed - 40\n",
      "[INFO] processed - 41\n",
      "[INFO] processed - 42\n",
      "[INFO] processed - 43\n",
      "[INFO] processed - 44\n",
      "[INFO] processed - 45\n",
      "[INFO] processed - 46\n",
      "[INFO] processed - 47\n",
      "[INFO] processed - 48\n",
      "[INFO] processed - 49\n",
      "[INFO] processed - 50\n",
      "[INFO] processed - 51\n",
      "[INFO] processed - 52\n",
      "[INFO] processed - 53\n",
      "[INFO] processed - 54\n",
      "[INFO] processed - 55\n",
      "[INFO] processed - 56\n",
      "[INFO] processed - 57\n",
      "[INFO] processed - 58\n",
      "[INFO] processed - 59\n",
      "[INFO] processed - 60\n",
      "[INFO] processed - 61\n",
      "[INFO] processed - 62\n",
      "[INFO] processed - 63\n",
      "[INFO] processed - 64\n",
      "[INFO] processed - 65\n",
      "[INFO] processed - 66\n",
      "[INFO] processed - 67\n",
      "[INFO] processed - 68\n",
      "[INFO] processed - 69\n",
      "[INFO] processed - 70\n",
      "[INFO] completed label - org\n",
      "[INFO] processed - 1\n",
      "[INFO] processed - 2\n",
      "[INFO] processed - 3\n",
      "[INFO] processed - 4\n",
      "[INFO] processed - 5\n",
      "[INFO] processed - 6\n",
      "[INFO] processed - 7\n",
      "[INFO] processed - 8\n",
      "[INFO] processed - 9\n",
      "[INFO] processed - 10\n",
      "[INFO] processed - 11\n",
      "[INFO] processed - 12\n",
      "[INFO] processed - 13\n",
      "[INFO] processed - 14\n",
      "[INFO] processed - 15\n",
      "[INFO] processed - 16\n",
      "[INFO] processed - 17\n",
      "[INFO] processed - 18\n",
      "[INFO] processed - 19\n",
      "[INFO] processed - 20\n",
      "[INFO] processed - 21\n",
      "[INFO] processed - 22\n",
      "[INFO] processed - 23\n",
      "[INFO] processed - 24\n",
      "[INFO] processed - 25\n",
      "[INFO] processed - 26\n",
      "[INFO] processed - 27\n",
      "[INFO] processed - 28\n",
      "[INFO] processed - 29\n",
      "[INFO] processed - 30\n",
      "[INFO] processed - 31\n",
      "[INFO] processed - 32\n",
      "[INFO] processed - 33\n",
      "[INFO] processed - 34\n",
      "[INFO] processed - 35\n",
      "[INFO] processed - 36\n",
      "[INFO] processed - 37\n",
      "[INFO] processed - 38\n",
      "[INFO] processed - 39\n",
      "[INFO] processed - 40\n",
      "[INFO] processed - 41\n",
      "[INFO] processed - 42\n",
      "[INFO] processed - 43\n",
      "[INFO] processed - 44\n",
      "[INFO] processed - 45\n",
      "[INFO] processed - 46\n",
      "[INFO] processed - 47\n",
      "[INFO] processed - 48\n",
      "[INFO] processed - 49\n",
      "[INFO] processed - 50\n",
      "[INFO] processed - 51\n",
      "[INFO] processed - 52\n",
      "[INFO] processed - 53\n",
      "[INFO] processed - 54\n",
      "[INFO] processed - 55\n",
      "[INFO] processed - 56\n",
      "[INFO] processed - 57\n",
      "[INFO] processed - 58\n",
      "[INFO] processed - 59\n",
      "[INFO] processed - 60\n",
      "[INFO] processed - 61\n",
      "[INFO] processed - 62\n",
      "[INFO] processed - 63\n",
      "[INFO] processed - 64\n",
      "[INFO] processed - 65\n",
      "[INFO] processed - 66\n",
      "[INFO] processed - 67\n",
      "[INFO] processed - 68\n",
      "[INFO] processed - 69\n",
      "[INFO] processed - 70\n",
      "[INFO] completed label - rec\n",
      "[STATUS] training labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[STATUS] training labels shape: (140,)\n",
      "[STATUS] saved model and weights to disk..\n",
      "[STATUS] features and labels saved..\n",
      "[STATUS] end time - 2018-10-05 09:55\n"
     ]
    }
   ],
   "source": [
    "# filter warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "# keras imports\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.applications.vgg19 import VGG19, preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.models import model_from_json\n",
    "from keras.layers import Input\n",
    "\n",
    "# other imports\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import h5py\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "# load the user configs\n",
    "with open('conf/conf.json') as f:    \n",
    "  config = json.load(f)\n",
    "\n",
    "# config variables\n",
    "model_name    = config[\"model\"]\n",
    "weights     = config[\"weights\"]\n",
    "include_top   = config[\"include_top\"]\n",
    "train_path    = config[\"train_path\"]\n",
    "features_path   = config[\"features_path\"]\n",
    "labels_path   = config[\"labels_path\"]\n",
    "test_size     = config[\"test_size\"]\n",
    "results     = config[\"results\"]\n",
    "model_path    = config[\"model_path\"]\n",
    "\n",
    "# start time\n",
    "print (\"[STATUS] start time - {}\".format(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\")))\n",
    "start = time.time()\n",
    "\n",
    "# create the pretrained models\n",
    "# check for pretrained weight usage or not\n",
    "# check for top layers to be included or not\n",
    "if model_name == \"vgg16\":\n",
    "  base_model = VGG16(weights=weights)\n",
    "  model = Model(input=base_model.input, output=base_model.get_layer('fc1').output)\n",
    "  image_size = (224, 224)\n",
    "elif model_name == \"vgg19\":\n",
    "  base_model = VGG19(weights=weights)\n",
    "  model = Model(input=base_model.input, output=base_model.get_layer('fc1').output)\n",
    "  image_size = (224, 224)\n",
    "\n",
    "else:\n",
    "  base_model = None\n",
    "\n",
    "print (\"[INFO] successfully loaded base model and model...\")\n",
    "\n",
    "# path to training dataset\n",
    "train_labels = os.listdir(train_path)\n",
    "\n",
    "# encode the labels\n",
    "print (\"[INFO] encoding labels...\")\n",
    "le = LabelEncoder()\n",
    "le.fit([tl for tl in train_labels])\n",
    "\n",
    "# variables to hold features and labels\n",
    "features = []\n",
    "labels   = []\n",
    "\n",
    "# loop over all the labels in the folder\n",
    "count = 1\n",
    "for i, label in enumerate(train_labels):\n",
    "  cur_path = train_path + \"/\" + label\n",
    "  count = 1\n",
    "  for image_path in glob.glob(cur_path + \"/*.png\"):\n",
    "    img = image.load_img(image_path, target_size=image_size)\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    feature = model.predict(x)\n",
    "    flat = feature.flatten()\n",
    "    features.append(flat)\n",
    "    labels.append(label)\n",
    "    print (\"[INFO] processed - \" + str(count))\n",
    "    count += 1\n",
    "  print (\"[INFO] completed label - \" + label)\n",
    "\n",
    "# encode the labels using LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le_labels = le.fit_transform(labels)\n",
    "\n",
    "# get the shape of training labels\n",
    "print (\"[STATUS] training labels: {}\".format(le_labels))\n",
    "print (\"[STATUS] training labels shape: {}\".format(le_labels.shape))\n",
    "\n",
    "# save features and labels\n",
    "h5f_data = h5py.File(features_path, 'w')\n",
    "h5f_data.create_dataset('dataset_1', data=np.array(features))\n",
    "\n",
    "h5f_label = h5py.File(labels_path, 'w')\n",
    "h5f_label.create_dataset('dataset_1', data=np.array(le_labels))\n",
    "\n",
    "h5f_data.close()\n",
    "h5f_label.close()\n",
    "\n",
    "# save model and weights\n",
    "model_json = model.to_json()\n",
    "with open(model_path + str(test_size) + \".json\", \"w\") as json_file:\n",
    "  json_file.write(model_json)\n",
    "\n",
    "# save weights\n",
    "model.save_weights(model_path + str(test_size) + \".h5\")\n",
    "print(\"[STATUS] saved model and weights to disk..\")\n",
    "\n",
    "print (\"[STATUS] features and labels saved..\")\n",
    "\n",
    "# end time\n",
    "end = time.time()\n",
    "print (\"[STATUS] end time - {}\".format(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a machine learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] features shape: (140, 4096)\n",
      "[INFO] labels shape: (140,)\n",
      "[INFO] training started...\n",
      "[INFO] splitted train and test data...\n",
      "[INFO] train data  : (126, 4096)\n",
      "[INFO] test data   : (14, 4096)\n",
      "[INFO] train labels: (126,)\n",
      "[INFO] test labels : (14,)\n",
      "[INFO] creating model...\n",
      "[INFO] confusion matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# organize imports\n",
    "from __future__ import print_function\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load the user configs\n",
    "with open('conf/conf.json') as f:    \n",
    "  config = json.load(f)\n",
    "\n",
    "# config variables\n",
    "test_size     = config[\"test_size\"]\n",
    "seed      = config[\"seed\"]\n",
    "features_path   = config[\"features_path\"]\n",
    "labels_path   = config[\"labels_path\"]\n",
    "results     = config[\"results\"]\n",
    "classifier_path = config[\"classifier_path\"]\n",
    "train_path    = config[\"train_path\"]\n",
    "num_classes   = config[\"num_classes\"]\n",
    "classifier_path = config[\"classifier_path\"]\n",
    "\n",
    "# import features and labels\n",
    "h5f_data  = h5py.File(features_path, 'r')\n",
    "h5f_label = h5py.File(labels_path, 'r')\n",
    "\n",
    "features_string = h5f_data['dataset_1']\n",
    "labels_string   = h5f_label['dataset_1']\n",
    "\n",
    "features = np.array(features_string)\n",
    "labels   = np.array(labels_string)\n",
    "\n",
    "h5f_data.close()\n",
    "h5f_label.close()\n",
    "\n",
    "# verify the shape of features and labels\n",
    "print (\"[INFO] features shape: {}\".format(features.shape))\n",
    "print (\"[INFO] labels shape: {}\".format(labels.shape))\n",
    "\n",
    "print (\"[INFO] training started...\")\n",
    "# split the training and testing data\n",
    "(trainData, testData, trainLabels, testLabels) = train_test_split(np.array(features),\n",
    "                                                                  np.array(labels),\n",
    "                                                                  test_size=test_size,\n",
    "                                                                  random_state=seed)\n",
    "\n",
    "print (\"[INFO] splitted train and test data...\")\n",
    "print (\"[INFO] train data  : {}\".format(trainData.shape))\n",
    "print (\"[INFO] test data   : {}\".format(testData.shape))\n",
    "print (\"[INFO] train labels: {}\".format(trainLabels.shape))\n",
    "print (\"[INFO] test labels : {}\".format(testLabels.shape))\n",
    "\n",
    "# use logistic regression as the model\n",
    "print (\"[INFO] creating model...\")\n",
    "model = LogisticRegression(random_state=seed)\n",
    "model.fit(trainData, trainLabels)\n",
    "\n",
    "# evaluate the model of test data\n",
    "preds = model.predict(testData)\n",
    "\n",
    "# display the confusion matrix\n",
    "print (\"[INFO] confusion matrix\")\n",
    "\n",
    "# plot the confusion matrix\n",
    "cm = confusion_matrix(testLabels, preds)\n",
    "sns.heatmap(cm,\n",
    "            annot=True,\n",
    "            cmap=\"Set2\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
